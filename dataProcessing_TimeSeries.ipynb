{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  #YY  MM DD hh mm WDIR WSPD GST  WVHT   DPD   APD MWD   PRES  ATMP  WTMP  DEWP  VIS  TIDE\n",
      "0  #yr  mo dy hr mn degT m/s  m/s     m   sec   s...                                      \n",
      "1  2019 01 01 00 00 228  0.3  1.0 99.00 99.00 99....                                      \n",
      "2  2019 01 01 00 06 329  0.0  0.7 99.00 99.00 99....                                      \n",
      "3  2019 01 01 00 12 270  0.0  0.4 99.00 99.00 99....                                      \n",
      "4  2019 01 01 00 18 171  0.9  1.0 99.00 99.00 99....                                      \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86547 entries, 0 to 86546\n",
      "Data columns (total 1 columns):\n",
      " #   Column                                                                                    Non-Null Count  Dtype \n",
      "---  ------                                                                                    --------------  ----- \n",
      " 0   #YY  MM DD hh mm WDIR WSPD GST  WVHT   DPD   APD MWD   PRES  ATMP  WTMP  DEWP  VIS  TIDE  86547 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 676.3+ KB\n",
      "None\n",
      "       #YY  MM DD hh mm WDIR WSPD GST  WVHT   DPD   APD MWD   PRES  ATMP  WTMP  DEWP  VIS  TIDE\n",
      "count                                               86547                                      \n",
      "unique                                              86547                                      \n",
      "top     #yr  mo dy hr mn degT m/s  m/s     m   sec   s...                                      \n",
      "freq                                                    1                                      \n",
      "#YY  MM DD hh mm WDIR WSPD GST  WVHT   DPD   APD MWD   PRES  ATMP  WTMP  DEWP  VIS  TIDE    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('/Users/jdhzy/Desktop/CS506_Final_Project/RawWaveData/Houston CAPL1/capl1h2019.txt')\n",
    "\n",
    "# Display the first few rows to inspect the structure\n",
    "print(data.head())\n",
    "\n",
    "# Show basic information about the dataset\n",
    "print(data.info())\n",
    "\n",
    "# Summarize numerical columns with descriptive statistics\n",
    "print(data.describe())\n",
    "\n",
    "# Check for missing or invalid values\n",
    "print(data.isnull().sum())  # Count of NaN values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['#YY', 'MM', 'DD', 'ATMP', 'WTMP', 'WVHT'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m columns_to_keep \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#YY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATMP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWTMP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWVHT\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns_to_keep\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Drop the first row from the DataFrame\u001b[39;00m\n\u001b[1;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['#YY', 'MM', 'DD', 'ATMP', 'WTMP', 'WVHT'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "columns_to_keep = ['#YY', 'MM', 'DD', 'ATMP', 'WTMP', 'WVHT']\n",
    "data = data[columns_to_keep]\n",
    "# Drop the first row from the DataFrame\n",
    "data = data.iloc[1:].reset_index(drop=True)\n",
    "# Display the DataFrame to verify\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill NA and extreme value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_invalid_values(data, column, invalid_values):\n",
    "    # Combine '#YY', 'MM', 'DD' into a single date column\n",
    "    data['date'] = pd.to_datetime(\n",
    "        dict(year=data['#YY'], month=data['MM'], day=data['DD']),\n",
    "        errors='coerce'\n",
    "    )\n",
    "\n",
    "    # Ensure there are no invalid or missing dates\n",
    "    if data['date'].isnull().any():\n",
    "        print(\"Warning: Some dates could not be parsed. Filling with nearby dates.\")\n",
    "        data['date'] = data['date'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "    # Replace invalid values (999, 99) with NaN for processing\n",
    "    data[column] = data[column].replace(invalid_values, np.nan)\n",
    "\n",
    "    # Group by 'date' to handle data at the daily level\n",
    "    grouped = data.groupby('date')\n",
    "\n",
    "    def process_group(group):\n",
    "        # If all values in the group are NaN, return as-is (handled later by interpolation)\n",
    "        if group[column].isnull().all():\n",
    "            return group\n",
    "\n",
    "        # Fill NaN within the day using the daily mean\n",
    "        group[column] = group[column].fillna(group[column].mean())\n",
    "        return group\n",
    "\n",
    "    # Apply the processing function to each group\n",
    "    data = grouped.apply(process_group).reset_index(drop=True)\n",
    "\n",
    "    # Handle days where all values are NaN\n",
    "    def interpolate_missing_days(data, column):\n",
    "        # Calculate daily means, including NaN for fully missing days\n",
    "        daily_mean = data.groupby('date')[column].mean()\n",
    "\n",
    "        # Interpolate missing daily means linearly\n",
    "        interpolated_mean = daily_mean.interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "        # Map interpolated daily means back to the original DataFrame\n",
    "        data[column] = data['date'].map(interpolated_mean)\n",
    "        return data\n",
    "\n",
    "    # Interpolate missing days for completely missing data\n",
    "    data = interpolate_missing_days(data, column)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some dates could not be parsed. Filling with nearby dates.\n",
      "Warning: Some dates could not be parsed. Filling with nearby dates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j6/gnlkxfsx0mz7c1ngs9mbs16m0000gn/T/ipykernel_70832/2395899682.py:11: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data['date'] = data['date'].fillna(method='ffill').fillna(method='bfill')\n",
      "/var/folders/j6/gnlkxfsx0mz7c1ngs9mbs16m0000gn/T/ipykernel_70832/2395899682.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data = grouped.apply(process_group).reset_index(drop=True)\n",
      "/var/folders/j6/gnlkxfsx0mz7c1ngs9mbs16m0000gn/T/ipykernel_70832/2395899682.py:11: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data['date'] = data['date'].fillna(method='ffill').fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some dates could not be parsed. Filling with nearby dates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j6/gnlkxfsx0mz7c1ngs9mbs16m0000gn/T/ipykernel_70832/2395899682.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data = grouped.apply(process_group).reset_index(drop=True)\n",
      "/var/folders/j6/gnlkxfsx0mz7c1ngs9mbs16m0000gn/T/ipykernel_70832/2395899682.py:11: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data['date'] = data['date'].fillna(method='ffill').fillna(method='bfill')\n",
      "/var/folders/j6/gnlkxfsx0mz7c1ngs9mbs16m0000gn/T/ipykernel_70832/2395899682.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data = grouped.apply(process_group).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#YY</th>\n",
       "      <th>MM</th>\n",
       "      <th>DD</th>\n",
       "      <th>ATMP</th>\n",
       "      <th>WTMP</th>\n",
       "      <th>WVHT</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.772222</td>\n",
       "      <td>28.212500</td>\n",
       "      <td>1.245833</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.772222</td>\n",
       "      <td>28.212500</td>\n",
       "      <td>1.245833</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.772222</td>\n",
       "      <td>28.212500</td>\n",
       "      <td>1.245833</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.772222</td>\n",
       "      <td>28.212500</td>\n",
       "      <td>1.245833</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.772222</td>\n",
       "      <td>28.212500</td>\n",
       "      <td>1.245833</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206914</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>25.808451</td>\n",
       "      <td>27.595833</td>\n",
       "      <td>1.254167</td>\n",
       "      <td>2023-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206915</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>25.808451</td>\n",
       "      <td>27.595833</td>\n",
       "      <td>1.254167</td>\n",
       "      <td>2023-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206916</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>25.808451</td>\n",
       "      <td>27.595833</td>\n",
       "      <td>1.254167</td>\n",
       "      <td>2023-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206917</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>25.808451</td>\n",
       "      <td>27.595833</td>\n",
       "      <td>1.254167</td>\n",
       "      <td>2023-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206918</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>25.808451</td>\n",
       "      <td>27.595833</td>\n",
       "      <td>1.254167</td>\n",
       "      <td>2023-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206919 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           #YY    MM    DD       ATMP       WTMP      WVHT       date\n",
       "0       2020.0   1.0   1.0  26.772222  28.212500  1.245833 2020-01-01\n",
       "1       2020.0   1.0   1.0  26.772222  28.212500  1.245833 2020-01-01\n",
       "2       2020.0   1.0   1.0  26.772222  28.212500  1.245833 2020-01-01\n",
       "3       2020.0   1.0   1.0  26.772222  28.212500  1.245833 2020-01-01\n",
       "4       2020.0   1.0   1.0  26.772222  28.212500  1.245833 2020-01-01\n",
       "...        ...   ...   ...        ...        ...       ...        ...\n",
       "206914  2023.0  12.0  31.0  25.808451  27.595833  1.254167 2023-12-31\n",
       "206915  2023.0  12.0  31.0  25.808451  27.595833  1.254167 2023-12-31\n",
       "206916  2023.0  12.0  31.0  25.808451  27.595833  1.254167 2023-12-31\n",
       "206917  2023.0  12.0  31.0  25.808451  27.595833  1.254167 2023-12-31\n",
       "206918  2023.0  12.0  31.0  25.808451  27.595833  1.254167 2023-12-31\n",
       "\n",
       "[206919 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace invalid values for each column\n",
    "data = fill_invalid_values(data, 'WTMP', invalid_values=[999, 99])\n",
    "data = fill_invalid_values(data, 'ATMP', invalid_values=[999, 99])\n",
    "data = fill_invalid_values(data, 'WVHT', invalid_values=[999, 99])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#YY     3\n",
      "MM      3\n",
      "DD      3\n",
      "ATMP    0\n",
      "WTMP    0\n",
      "WVHT    0\n",
      "date    0\n",
      "dtype: int64\n",
      "After dropping NaN:\n",
      "#YY     0\n",
      "MM      0\n",
      "DD      0\n",
      "ATMP    0\n",
      "WTMP    0\n",
      "WVHT    0\n",
      "date    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check for nan \n",
    "print(data.isnull().sum())\n",
    "data = data.dropna(subset=['#YY', 'MM', 'DD'])\n",
    "print(\"After dropping NaN:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#YY</th>\n",
       "      <th>MM</th>\n",
       "      <th>DD</th>\n",
       "      <th>ATMP</th>\n",
       "      <th>WTMP</th>\n",
       "      <th>WVHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.772222</td>\n",
       "      <td>28.212500</td>\n",
       "      <td>1.245833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.189928</td>\n",
       "      <td>28.054167</td>\n",
       "      <td>1.108333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.284722</td>\n",
       "      <td>27.933333</td>\n",
       "      <td>1.212500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.873611</td>\n",
       "      <td>27.754167</td>\n",
       "      <td>1.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.072222</td>\n",
       "      <td>27.808333</td>\n",
       "      <td>1.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>25.494118</td>\n",
       "      <td>27.762500</td>\n",
       "      <td>1.295833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.529167</td>\n",
       "      <td>27.775000</td>\n",
       "      <td>1.337500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>25.337324</td>\n",
       "      <td>27.816667</td>\n",
       "      <td>1.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.756643</td>\n",
       "      <td>27.658333</td>\n",
       "      <td>1.091667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>25.808451</td>\n",
       "      <td>27.595833</td>\n",
       "      <td>1.254167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1453 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         #YY    MM    DD       ATMP       WTMP      WVHT\n",
       "0     2020.0   1.0   1.0  26.772222  28.212500  1.245833\n",
       "1     2020.0   1.0   2.0  27.189928  28.054167  1.108333\n",
       "2     2020.0   1.0   3.0  26.284722  27.933333  1.212500\n",
       "3     2020.0   1.0   4.0  26.873611  27.754167  1.291667\n",
       "4     2020.0   1.0   5.0  25.072222  27.808333  1.233333\n",
       "...      ...   ...   ...        ...        ...       ...\n",
       "1448  2023.0  12.0  27.0  25.494118  27.762500  1.295833\n",
       "1449  2023.0  12.0  28.0  25.529167  27.775000  1.337500\n",
       "1450  2023.0  12.0  29.0  25.337324  27.816667  1.183333\n",
       "1451  2023.0  12.0  30.0  25.756643  27.658333  1.091667\n",
       "1452  2023.0  12.0  31.0  25.808451  27.595833  1.254167\n",
       "\n",
       "[1453 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def keep_max_wvht_per_day(data):\n",
    "    \"\"\"\n",
    "    Keep only the row with the maximum WVHT value for each day and drop the rest.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Input dataset with '#YY', 'MM', 'DD', and 'WVHT' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataset with only one row per day, corresponding to the maximum WVHT.\n",
    "    \"\"\"\n",
    "    # Combine '#YY', 'MM', 'DD' into a single date column\n",
    "    data['date'] = pd.to_datetime(\n",
    "        dict(year=data['#YY'], month=data['MM'], day=data['DD']),\n",
    "        errors='coerce'\n",
    "    )\n",
    "\n",
    "    # Ensure that the 'date' column was created successfully\n",
    "    if data['date'].isnull().any():\n",
    "        print(\"Warning: Some dates could not be parsed. Dropping invalid rows.\")\n",
    "        data = data.dropna(subset=['date'])\n",
    "\n",
    "    # Group by 'date' and find the row with the maximum WVHT for each day\n",
    "    max_wvht_data = (\n",
    "        data.loc[data.groupby('date')['WVHT'].idxmax()]\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Drop the temporary 'date' column if not needed\n",
    "    max_wvht_data = max_wvht_data.drop(columns=['date'])\n",
    "\n",
    "    return max_wvht_data\n",
    "\n",
    "data = keep_max_wvht_per_day(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#YY</th>\n",
       "      <th>MM</th>\n",
       "      <th>DD</th>\n",
       "      <th>ATMP</th>\n",
       "      <th>WTMP</th>\n",
       "      <th>WVHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.772222</td>\n",
       "      <td>28.212500</td>\n",
       "      <td>1.245833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.189928</td>\n",
       "      <td>28.054167</td>\n",
       "      <td>1.108333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.284722</td>\n",
       "      <td>27.933333</td>\n",
       "      <td>1.212500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.873611</td>\n",
       "      <td>27.754167</td>\n",
       "      <td>1.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.072222</td>\n",
       "      <td>27.808333</td>\n",
       "      <td>1.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>25.494118</td>\n",
       "      <td>27.762500</td>\n",
       "      <td>1.295833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.529167</td>\n",
       "      <td>27.775000</td>\n",
       "      <td>1.337500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>25.337324</td>\n",
       "      <td>27.816667</td>\n",
       "      <td>1.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.756643</td>\n",
       "      <td>27.658333</td>\n",
       "      <td>1.091667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>25.808451</td>\n",
       "      <td>27.595833</td>\n",
       "      <td>1.254167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1453 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         #YY    MM    DD       ATMP       WTMP      WVHT\n",
       "0     2020.0   1.0   1.0  26.772222  28.212500  1.245833\n",
       "1     2020.0   1.0   2.0  27.189928  28.054167  1.108333\n",
       "2     2020.0   1.0   3.0  26.284722  27.933333  1.212500\n",
       "3     2020.0   1.0   4.0  26.873611  27.754167  1.291667\n",
       "4     2020.0   1.0   5.0  25.072222  27.808333  1.233333\n",
       "...      ...   ...   ...        ...        ...       ...\n",
       "1448  2023.0  12.0  27.0  25.494118  27.762500  1.295833\n",
       "1449  2023.0  12.0  28.0  25.529167  27.775000  1.337500\n",
       "1450  2023.0  12.0  29.0  25.337324  27.816667  1.183333\n",
       "1451  2023.0  12.0  30.0  25.756643  27.658333  1.091667\n",
       "1452  2023.0  12.0  31.0  25.808451  27.595833  1.254167\n",
       "\n",
       "[1453 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      #YY   MM   DD      ATMP      WTMP      WVHT\n",
      "0  2020.0  1.0  1.0  0.395523  0.521815  0.367322\n",
      "1  2020.0  1.0  2.0  0.445842  0.488656  0.326781\n",
      "2  2020.0  1.0  3.0  0.336797  0.463351  0.357494\n",
      "3  2020.0  1.0  4.0  0.407737  0.425829  0.380835\n",
      "4  2020.0  1.0  5.0  0.190735  0.437173  0.363636\n"
     ]
    }
   ],
   "source": [
    "# Select columns to normalize\n",
    "columns_to_normalize = ['ATMP', 'WTMP', 'WVHT']\n",
    "data_to_normalize = data[columns_to_normalize]\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "normalized_data = scaler.fit_transform(data_to_normalize)\n",
    "\n",
    "# Replace original columns with normalized values\n",
    "data_normalized = data.copy()\n",
    "data_normalized[columns_to_normalize] = normalized_data\n",
    "\n",
    "# Verify the normalization\n",
    "print(data_normalized.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only Time directly related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. to CSV\n",
    "output_file = \"merged_TimeWVHT_data.csv\"\n",
    "data.to_csv(output_file, index=False)\n",
    "\n",
    "data = pd.read_csv(\"merged_TimeWVHT_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
